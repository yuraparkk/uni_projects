{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "67b59e97",
   "metadata": {},
   "source": [
    "Upload and first look"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "170fc460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 13854 entries, 0 to 13853\n",
      "Data columns (total 5 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  13854 non-null  int64 \n",
      " 1   Title       13854 non-null  object\n",
      " 2   Poem        13854 non-null  object\n",
      " 3   Poet        13854 non-null  object\n",
      " 4   Tags        12899 non-null  object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 541.3+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Poem</th>\n",
       "      <th>Poet</th>\n",
       "      <th>Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\r\\n\\r\\n                    Objects Used to Pr...</td>\n",
       "      <td>\\r\\n\\r\\nDog bone, stapler,\\r\\n\\r\\ncribbage boa...</td>\n",
       "      <td>Michelle Menting</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\r\\n\\r\\n                    The New Church\\r\\n...</td>\n",
       "      <td>\\r\\n\\r\\nThe old cupola glinted above the cloud...</td>\n",
       "      <td>Lucia Cherciu</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Title  \\\n",
       "0           0  \\r\\n\\r\\n                    Objects Used to Pr...   \n",
       "1           1  \\r\\n\\r\\n                    The New Church\\r\\n...   \n",
       "\n",
       "                                                Poem              Poet Tags  \n",
       "0  \\r\\n\\r\\nDog bone, stapler,\\r\\n\\r\\ncribbage boa...  Michelle Menting  NaN  \n",
       "1  \\r\\n\\r\\nThe old cupola glinted above the cloud...     Lucia Cherciu  NaN  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "df = pd.read_csv(\"data/poetry_dataset.csv\")\n",
    "\n",
    "df.info()        \n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e2bf68d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Poem 0\n",
      "'\\r\\n\\r\\nDog bone, stapler,\\r\\n\\r\\ncribbage board, garlic press\\r\\n\\r\\n     because this window is loose—lacks\\r\\n\\r\\nsuction, lacks grip.\\r\\n\\r\\nBungee cord, bootstrap,\\r\\n\\r\\ndog leash, leather belt\\r\\n\\r\\n     because this window had sash cords.\\r\\n\\r\\nThey frayed. They broke.\\r\\n\\r\\nFeather duster, thatch of straw, empty\\r\\n\\r\\nbottle '\n",
      "\n",
      "Poem 20\n",
      "'\\r\\n\\r\\n               I got a call from the White House, from the\\r\\n\\r\\nPresident himself, asking me if I’d do him a personal\\r\\n\\r\\nfavor. I like the President, so I said, “Sure, Mr.\\r\\n\\r\\nPresident, anything you like.” He said, “Just act\\r\\n\\r\\nlike nothing’s going on. Act normal. That would\\r\\n\\r\\nmean the world to m'\n",
      "\n",
      "Poem 18\n",
      "'\\r\\n\\r\\nWhy are you still seventeen\\r\\n\\r\\nand drifting like a dog after dark,\\r\\n\\r\\ndragging a shadow you’ve found?\\r\\n\\r\\n \\r\\n\\r\\nPut it back where it belongs,\\r\\n\\r\\nand that bend of river, too. That’s not the road\\r\\n\\r\\nyou want, though you have it to yourself.\\r\\n\\r\\n \\r\\n\\r\\nGone are the cars that crawl to town\\r\\n\\r\\nfrom the re'\n"
     ]
    }
   ],
   "source": [
    "sample_idx = [0, 20, 18]                    \n",
    "\n",
    "for i in sample_idx:\n",
    "    text = df.loc[i, \"Poem\"]\n",
    "    print(f\"\\nPoem {i}\\n{repr(text[:300])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d199ff36",
   "metadata": {},
   "source": [
    "Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "68fdaa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Poem_clean'] = (\n",
    "    df['Poem']\n",
    "      .str.replace(                 #replace \\r\\n into tokens\n",
    "          r'(?:\\r\\n|\\r|\\n){1,}',\n",
    "          lambda m: '<SB>' if m.group(0).replace('\\r\\n', '\\n')\n",
    "                                      .replace('\\r', '\\n').count('\\n') >= 4\n",
    "                      else '<LB>',\n",
    "          regex=True)\n",
    "      .str.replace(r'(?:<SB>\\s*)+', '<SB>', regex=True)\n",
    "      .str.replace(r'^<LB>\\s*|\\s*<LB>$', '', regex=True)\n",
    "      .str.strip()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0c9b0139",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"Unnamed: 0\"])    #drop redundant column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "524166bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                    Title                Poet                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           Poem_clean\n",
      "                             \\r\\n\\r\\n                    The Idea\\r\\n\\r\\n                         Mark Strand                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     <SB>for Nolan Miller<SB>For us, too, there was a wish to possess<LB>Something beyond the world we knew, beyond ourselves,<LB>Beyond our power to imagine, something nevertheless<LB>In which we might see ourselves; and this desire<LB>Came always in passing, in waning light, and in such cold<LB>That ice on the valley’s lakes cracked and rolled,<LB>And blowing snow covered what earth we saw,<LB>And scenes from the past, when they surfaced again,<LB>Looked not as they had, but ghostly and white<LB>Among false curves and hidden erasures;<LB>And never once did we feel we were close<LB>Until the night wind said, “Why do this,<LB>Especially now? Go back to the place you belong;”<LB>And there appeared , with its windows glowing, small,<LB>In the distance, in the frozen reaches, a cabin;<LB>And we stood before it, amazed at its being there,<LB>And would have gone forward and opened the door,<LB>And stepped into the glow and warmed ourselves there,<LB>But that it was ours by not being ours,<LB>And should remain empty. That was the idea.\n",
      "\\r\\n\\r\\n                    Lectures to Women on Physical Science\\r\\n\\r\\n                 James Clerk Maxwell                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      I.<LB>    PLACE. —A small alcove with dark curtains.<LB>    The class consists of one member.<LB>       SUBJECT.—Thomson’s Mirror Galvanometer.\n",
      "                           \\r\\n\\r\\n                    Marginalia\\r\\n\\r\\n                      Deborah Warren                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               Finding an old book on a basement shelf—   gray, spine bent—and reading it again,   I met my former, unfamiliar, self,   some of her notes and scrawls so alien   that, though I tried, I couldn't get (behind   this gloss or that) back to the time she wrote   to guess what experiences she had in mind,   the living context of some scribbled note;   or see the girl beneath the purple ink   who chose this phrase or that to underline,   the mood, the boy, that lay behind her thinking—    but they were thoughts I recognized as mine;   and though there were words I couldn't even read,   blobs and cross-outs; and though not a jot   remained of her old existence—I agreed   with the young annotator's every thought:   A clever girl. So what would she see fit   to comment on—and what would she have to say   about the years that she and I have written   since—before we put the book away?\n",
      "                 \\r\\n\\r\\n                    The Book of Equality\\r\\n\\r\\n                    Daniel Borzutzky Here the readers gather to watch the books die. They die suddenly, as if thrown from an airplane, or from spontaneous cardiac arrest. They live, and then suddenly they die, and the reader who watches this is at the moment of the books' death bombarded with images documented through the smiling lipstick face of a journalist who has shown up to report on the death of the books. The milk was poisoned and forty-two babies died, she laughs, as she fondles the ashes of the dead books. And the death of forty-two babies is equal in value to the death of this book which is equal in value to the ninety-year old woman who shot herself while the sheriff waited at her door with an eviction notice which is equal in value to the collapsing of the global economy which is equal to the military in country XYZ seizing the land of the semi-nomadic hunters and cultivators of crops who have lived in the local rain forest for thousands of years. The reader opens a dead book and finds an infinite amount of burnt ash between the bindings, and when the ash blows in the wind the lipstick says that every death in the world is equal to every other death in the world which is equal to every birth in the world which is equal to every act of dismemberment which is equal to the death of a jungle which is equal to the collapse of the global economy; and hey look there’s another lady falling out of a window; she looks about equal to the poet hurled out of his country for words he wrote but which did not belong to him and whose death is about equal to the girl who was shot on the bus on her way to school this morning which is just about the same as the bearded man whose head was shoved into a sac while water was dumped over it and he died for an instant and came back to life and talked and talked and that’s about equal to the steroid illegally injected into the arm of a beautiful man who makes forty million dollars a year for injecting his arms with steroids so he can more skillfully wave a wooden stick at a ball, and in the ash we see the truest democracy there ever was: hey look it’s a little baby found in a dumpster how equal you are says the smiling lipstick to the civilized nation whose citizens walk the flooded streets looking for their homes, and in the ashes of the dead book the dead streets are equal to the eating disorders of movie stars which are equal to the dead soldiers who are equal to the homeruns which are equal to the bomb dropped by country ABC over weddings in the village of country XYZ which is equal to the earth swallowing up and devouring all of its foreigners which is just about equal to the decline in literacy in the most educated nation in the planet. There is no end to this book. There are no paragraph breaks to interrupt the smiling lipstick that goes on and on in one string of ashy words about how the declaration of peace is equal to the resumption of war and how the bodies that fall are equal to the birds that ascend and how the bomb in the Eiffel Tower is equal to the rising cost of natural gas, and the murmurs of the voices in the mud are equal to the murmurs of the expensive suits falling out of buildings and these are equal to the silence that kills with one breath and coddles life with another.\n",
      "                                \\r\\n\\r\\n                    Psalm\\r\\n\\r\\n                        George Oppen                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         <SB>Veritas sequitur ...<SB>In the small beauty of the forest<LB>The wild deer bedding down—<LB>That they are there!<LB>                              Their eyes<LB>Effortless, the soft lips<LB>Nuzzle and the alien small teeth<LB>Tear at the grass<LB>                              The roots of it<LB>Dangle from their mouths<LB>Scattering earth in the strange woods.<LB>They who are there.<LB>                              Their paths<LB>Nibbled thru the fields, the leaves that shade them<LB>Hang in the distances<LB>Of sun<LB>                              The small nouns<LB>Crying faith<LB>In this in which the wild deer   <LB>Startle, and stare out.\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    df.sample(5)[['Title','Poet','Poem_clean']]\n",
    "      .to_string(index=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "29196c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "8\n",
      "1\n",
      "99\n",
      "     Poem_clean\n",
      "919        <SB>\n",
      "945        <SB>\n",
      "4091       <SB>\n",
      "4191       <SB>\n",
      "4193       <SB>\n"
     ]
    }
   ],
   "source": [
    "# check for missing poems\n",
    "missing = df['Poem_clean'].isnull().sum()\n",
    "print(missing)\n",
    "\n",
    "# check for duplicates\n",
    "dupes = df.duplicated(subset=['Title','Poem_clean','Poet']).sum()\n",
    "print(dupes)\n",
    "\n",
    "# check for empty strings \n",
    "empty = (df['Poem_clean'].str.strip() == \"\").sum()\n",
    "print(empty)\n",
    "\n",
    "# rows that were formerly empty but now just tokens\n",
    "token_only = df['Poem_clean'].isin(['<LB>', '<SB>'])\n",
    "print(token_only.sum())\n",
    "print(df.loc[token_only, ['Poem_clean']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fa0978b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n"
     ]
    }
   ],
   "source": [
    "empty0 = (df['Poem'].str.strip() == \"\").sum()   \n",
    "print(empty0)\n",
    "\n",
    "#those cells were empty before cleaning, so we will drop them as well as duplicates and only-tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "de7232ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3c/fhp40yqx0dj74mcgn901zq5w0000gn/T/ipykernel_44211/1806552671.py:5: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  df = df[~token_only].reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "df = df[df[\"Poem_clean\"].str.strip().astype(bool)].reset_index(drop=True)\n",
    "\n",
    "df = df.drop_duplicates(subset=[\"Title\",\"Poem_clean\",\"Poet\"]).reset_index(drop=True)\n",
    "\n",
    "df = df[~token_only].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4ee517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines & Stanzas\n",
      "            n_lines     n_stanzas  avg_lines_per_stanza\n",
      "count  13751.000000  13751.000000          13751.000000\n",
      "mean      27.230020      1.729692             23.956281\n",
      "std       49.276962      7.834730             44.168166\n",
      "min        1.000000      0.000000              0.000000\n",
      "25%        1.000000      1.000000              1.000000\n",
      "50%       16.000000      1.000000             15.000000\n",
      "75%       33.000000      1.000000             30.000000\n",
      "max     1344.000000    637.000000           1344.000000 \n",
      "\n",
      "Words per Line\n",
      "count    13751.000000\n",
      "mean        71.079127\n",
      "std        284.936695\n",
      "min          0.000000\n",
      "25%          6.062500\n",
      "50%          8.000000\n",
      "75%         69.000000\n",
      "max       9713.000000\n",
      "Name: avg_words_per_line, dtype: float64 \n",
      "\n",
      "Total Words per Poem\n",
      "count    13751.000000\n",
      "mean       251.321140\n",
      "std        442.320771\n",
      "min          0.000000\n",
      "25%         99.000000\n",
      "50%        153.000000\n",
      "75%        263.000000\n",
      "max      15713.000000\n",
      "Name: total_words, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "def stats(df):\n",
    "    # per-poem metrics\n",
    "    metrics = df['Poem_clean'].apply(lambda text: pd.Series({\n",
    "        'n_stanzas':            len([s for s in text.split('<SB>') if s.strip()]),\n",
    "        'n_lines':              sum(len(st.split('<LB>')) for st in text.split('<SB>')),\n",
    "        'avg_lines_per_stanza': (\n",
    "            lambda L,S: L/S if S else 0\n",
    "        )(\n",
    "            sum(len(st.split('<LB>')) for st in text.split('<SB>')),\n",
    "            len([s for s in text.split('<SB>') if s.strip()])\n",
    "        ),\n",
    "        'avg_words_per_line': (\n",
    "            lambda wpl: sum(wpl)/len(wpl) if wpl else 0\n",
    "        )([\n",
    "            len(line.split())\n",
    "            for st in text.split('<SB>')\n",
    "            for line in st.split('<LB>')\n",
    "            if line.strip()\n",
    "        ]),\n",
    "        'total_words':          sum(\n",
    "            len(line.split())\n",
    "            for st in text.split('<SB>')\n",
    "            for line in st.split('<LB>')\n",
    "            if line.strip()\n",
    "        )\n",
    "    }))\n",
    "\n",
    "    print(\"Lines & Stanzas\")\n",
    "    print(metrics[['n_lines','n_stanzas','avg_lines_per_stanza']].describe(), \"\\n\")\n",
    "    print(\"Words per Line\")\n",
    "    print(metrics['avg_words_per_line'].describe(), \"\\n\")\n",
    "    print(\"Total Words per Poem\")\n",
    "    print(metrics['total_words'].describe(), \"\\n\")\n",
    "\n",
    "\n",
    "stats(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c2784661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— \n",
      "\n",
      "                    Invisible Fish\n",
      "\n",
      "                 by Joy Harjo (avg words/line = 57.0)\n",
      "Invisible fish swim this ghost ocean now described by waves of sand, by water-worn rock. Soon the fish will learn to walk. Then humans will come ashore and paint dreams on the dying stone. Then later, much later, the ocean floor will be punctuated by Chevy trucks, carrying the dreamers’ decendants, who are going to the store.\n",
      "…\n",
      "\n",
      "— \n",
      "\n",
      "                    Don’t Bother the Earth Spirit\n",
      "\n",
      "                 by Joy Harjo (avg words/line = 107.0)\n",
      "Don’t bother the earth spirit who lives here. She is working on a story. It is the oldest story in the world and it is delicate, changing. If she sees you watching she will invite you in for coffee, give you warm bread, and you will be obligated to stay and listen. But this is no ordinary story. You will have to endure earthquakes, lightning, the deaths of all those you love, the most blinding beauty. It’s a story so compelling you may never want to leave; this is how she traps you. See that sto\n",
      "…\n",
      "\n",
      "— \n",
      "\n",
      "                    [\"Hour in which I consider hydrangea\"]\n",
      "\n",
      "                 by Simone White (avg words/line = 309.0)\n",
      "Hour in which I consider hydrangea, a salt or sand plant, varietal, the question of varietals, the diet of every mother I know, 5 pounds feels like 20, I have lost … I have lost, yes, a sense of my own possible beauty, grown external, I externalize beauty. Beauty occurs on the surface of plants; the sun darkens the skin of my child, he is so small, he is beautiful (I can see; it is obvious) and everything about him is beautiful. His hand swells from the bite [spread?] of some insect[’s] venom be\n",
      "…\n",
      "\n",
      "— \n",
      "\n",
      "from What the Heart Longs For When It Only Knows Heat [\"We spend the afternoon together watching a docudrama...\"]\n",
      "\n",
      "                 by Sueyeun Juliette Lee (avg words/line = 116.0)\n",
      "We spend the afternoon together watching a docudrama about wild horses that roamed the ancient Arctic Circle. Surprisingly sleek, built for speed and not the weather, they were remarkable for their recklessness. They careen headlong down ice bluffs to fall into a broken heap. We can hear the small, tinny sounds of their terror as they plunge across vast, glowing glacial faces. All of this takes place alongside an abstractly relentless gunmetal sea. I can feel you turn to me, wetness marking the \n",
      "…\n",
      "\n",
      "— \n",
      "\n",
      "                    My Mother upon Hearing News of Her Mother’s Death\n",
      "\n",
      "                 by Cathy Linh Che (avg words/line = 75.0)\n",
      "She opened her mouth and a moose came out, a donkey, and an ox—out of her mouth, years of animal grief. I lead her to the bed. She held my hand and followed. She said, Chết rồi, and like that, the cord was cut, the thread snapped, and the cable that tied my mother to her mother broke. And now her eyes red as a market fish. And now, she dropped like laundry on the bed.<LB> <LB>The furniture moved toward her, the kitchen knives and spoons, the vibrating spoons—they dragged the tablecloth, the corn\n",
      "…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics = df['Poem_clean'].apply(lambda text: pd.Series({\n",
    "    'n_stanzas': len([s for s in text.split('<SB>') if s.strip()]),\n",
    "    'n_lines':   sum(len(st.split('<LB>')) for st in text.split('<SB>')),\n",
    "    'avg_words_per_line': (\n",
    "        lambda wpl: sum(wpl)/len(wpl) if wpl else 0)(\n",
    "            [len(l.split())\n",
    "             for st in text.split('<SB>')\n",
    "             for l in st.split('<LB>')\n",
    "             if l.strip()]\n",
    "    )\n",
    "}))\n",
    "\n",
    "# select the “long‐line” outliers\n",
    "outliers = metrics[metrics['avg_words_per_line'] > 50].head(5)\n",
    "\n",
    "# show \n",
    "for idx in outliers.index:\n",
    "    print(f\"— {df.at[idx,'Title']} by {df.at[idx,'Poet']} \"\n",
    "          f\"(avg words/line = {outliers.at[idx,'avg_words_per_line']:.1f})\")\n",
    "    print(df.at[idx,'Poem_clean'][:500].replace('\\n', '\\\\n'))\n",
    "    print(\"…\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28f8bf60",
   "metadata": {},
   "source": [
    "A very long 1-liners is ok, it is just prose poems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5262bcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poem with max lines/stanzas\n",
      "Title    \\r\\n\\r\\n                    Song of Myself (18...\n",
      "Poet                                          Walt Whitman\n",
      "Name: 12981, dtype: object\n",
      "n_lines      1344.0\n",
      "n_stanzas       1.0\n",
      "Name: 12981, dtype: float64\n",
      "\n",
      "Snippet:\n",
      "1<LB>I celebrate myself, and sing myself,<LB>And what I assume you shall assume,<LB>For every atom belonging to me as good belongs to you.<LB>I loafe and invite my soul,<LB>I lean and loafe at my ease observing a spear of summer grass.<LB>My tongue, every atom of my blood, form’d from this soil, this air,<LB>Born here of parents born here from parents the same, and their parents the same,<LB>I, now thirty-seven years old in perfect health begin,<LB>Hoping to cease not till death.<LB>Creeds and s …\n",
      "\n",
      "Poem with max avg words-per-line\n",
      "Title    \\r\\n\\r\\n                    Venus and Adonis\\r...\n",
      "Poet                                   William Shakespeare\n",
      "Name: 2390, dtype: object\n",
      "avg_words_per_line    9713.0\n",
      "Name: 2390, dtype: float64\n",
      "\n",
      "Snippet:\n",
      "<LB> Even as the sun with purple-colour’d face      Had ta’en his last leave of the weeping morn,      Rose-cheek’d Adonis tried him to the chase;      Hunting he lov’d, but love he laugh’d to scorn;              Sick-thoughted Venus makes amain unto him,        And like a bold-fac’d suitor ‘gins to woo him.        ‘Thrice fairer than myself,’ thus she began,      ‘The field’s chief flower, sweet above compare,              Stain to all nymphs, more lovely than a man,      More white and red tha …\n"
     ]
    }
   ],
   "source": [
    "# the poem with the most lines\n",
    "idx_max_lines = metrics['n_lines'].idxmax()\n",
    "print(\"Poem with max lines/stanzas\")\n",
    "print(df.loc[idx_max_lines, ['Title','Poet']])\n",
    "print(metrics.loc[idx_max_lines, ['n_lines','n_stanzas']])\n",
    "print(\"\\nSnippet:\")\n",
    "print(df.at[idx_max_lines, 'Poem_clean'][:500], \"…\\n\")\n",
    "\n",
    "# the poem with the highest words-per-line\n",
    "idx_max_wpl = metrics['avg_words_per_line'].idxmax()\n",
    "print(\"Poem with max avg words-per-line\")\n",
    "print(df.loc[idx_max_wpl, ['Title','Poet']])\n",
    "print(metrics.loc[idx_max_wpl, ['avg_words_per_line']])\n",
    "print(\"\\nSnippet:\")\n",
    "print(df.at[idx_max_wpl, 'Poem_clean'][:500], \"…\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed07e37",
   "metadata": {},
   "source": [
    "1. the poem with most lines is ok, it is indeed a very long poem by Walt Whitmen\n",
    "2. the poem with most words per line is bugged, spaces are not seen as LB or SB here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50b65b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5092 poems with runs of ≥3 spaces\n",
      "— \n",
      "\n",
      "                    Objects Used to Prop Open a Window\n",
      "\n",
      "                 by Michelle Menting\n",
      "Dog bone, stapler,<LB>cribbage board, garlic press<LB>     because this window is loose—lacks<LB>suction, lacks grip.<LB>Bungee cord, bootstrap,<LB>dog leash, leather belt<LB>     because this window \n",
      "…\n",
      "\n",
      "— \n",
      "\n",
      "                    scars\n",
      "\n",
      "                 by Truong Tran\n",
      "my father’s body is a map<LB>a record of his journey<LB> <LB>he carries a bullet<LB>lodged in his left thigh<LB>there is a hollow where it entered<LB>a protruding bump where it sleeps<LB>the doctors s\n",
      "…\n",
      "\n",
      "— \n",
      "\n",
      "                    what remains two\n",
      "\n",
      "                 by Truong Tran\n",
      "it has long been forgotten this practice of the mother<LB>weaning a child she crushes the seeds of a green<LB>chili rubs it to her nipple what the child feels<LB>she too will   share in this act   of \n",
      "…\n",
      "\n",
      "— \n",
      "\n",
      "                    Yes\n",
      "\n",
      "                 by Debora Greger\n",
      "<SB>Yes, your childhood now a legend of fountains<LB>                                                         —jorge gullén<SB>Yes, your childhood, now a legend<LB>gone to weeds, still remembers the g\n",
      "…\n",
      "\n",
      "— \n",
      "\n",
      "                    Sleeping with Butler’s Lives of the Saints\n",
      "\n",
      " by Eugene Gloria\n",
      "<SB>After Octavio Paz<SB>What’s most human must drive<LB>an arrow to the heart.<LB> <LB>Ghosts, too, must abide by this directive<LB>& remain transparent,<LB> <LB>going about their business in old hou\n",
      "…\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "space_mask = df['Poem_clean'].str.contains(r' {3,}')\n",
    "\n",
    "print(f\"{space_mask.sum()} poems with runs of ≥3 spaces\")\n",
    "\n",
    "for idx, row in df[space_mask].head(5).iterrows():\n",
    "    title, poet = row['Title'], row['Poet']\n",
    "    snippet = row['Poem_clean'][:200].replace('\\n', '\\\\n')\n",
    "    print(f\"— {title} by {poet}\")\n",
    "    print(snippet)\n",
    "    print(\"…\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d962700",
   "metadata": {},
   "source": [
    "Some spaceruns are just spaces, we can neglect them by excluding those poems that have LBs and SBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "bb8ef006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved to poems_with_multi_space_runs.csv\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "# select poems with NO tokens\n",
    "mask_no_tokens = ~df['Poem_clean'].str.contains(r'<LB>|<SB>', regex=True)\n",
    "subset = df.loc[mask_no_tokens].copy()\n",
    "\n",
    "# per-poem histogram of space-runs (≥ 2 spaces)\n",
    "subset['run_hist'] = (\n",
    "    subset['Poem_clean']\n",
    "      .str.findall(r' {2,}')\n",
    "      .apply(lambda lst: collections.Counter(len(r) for r in lst))\n",
    ")\n",
    "\n",
    "# keep poems that have at least 2 distinct run-lengths\n",
    "subset_multi = subset[subset['run_hist'].apply(lambda h: len(h) >= 2)].copy()\n",
    "\n",
    "# save to CSV for mannual check\n",
    "subset_multi[['Title','Poet','run_hist','Poem_clean']].to_csv(\n",
    "    \"poems_with_multi_space_runs.csv\", index=False\n",
    ")\n",
    "\n",
    "print(\"Saved to poems_with_multi_space_runs.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c393c41",
   "metadata": {},
   "source": [
    "Mannual check revealed that there are 617 poems that have no SB and LB and where spaceruns differ from 2 to 256, any patterns are hardly seen. I think it is easier to drop those 166 poems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2e8f3a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropping 617 poems\n",
      "Remaining poems: 13134\n",
      "Saved to data/processed/final_clean.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# poems that still have NO tokens\n",
    "mask_no_tokens = ~df['Poem_clean'].str.contains(r'<LB>|<SB>', regex=True)\n",
    "subset = df.loc[mask_no_tokens].copy()\n",
    "\n",
    "# histogram of space-runs (≥2 spaces)\n",
    "subset['run_hist'] = (\n",
    "    subset['Poem_clean']\n",
    "      .str.findall(r' {2,}')\n",
    "      .apply(lambda lst: collections.Counter(len(s) for s in lst))\n",
    ")\n",
    "\n",
    "# rows to drop: poems with ≥2 distinct run-lengths\n",
    "mask_drop = subset['run_hist'].apply(lambda h: len(h) >= 2)\n",
    "print(\"Dropping\", mask_drop.sum(), \"poems\")\n",
    "\n",
    "df_clean = df.drop(index=subset.loc[mask_drop].index).reset_index(drop=True)\n",
    "print(\"Remaining poems:\", len(df_clean))\n",
    "\n",
    "os.makedirs(\"processed\", exist_ok=True)\n",
    "df_clean.to_csv(\"data/processed/final_clean.csv\", index=False)\n",
    "print(\"Saved to data/processed/final_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cf986591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines & Stanzas\n",
      "            n_lines     n_stanzas  avg_lines_per_stanza\n",
      "count  13751.000000  13751.000000          13751.000000\n",
      "mean      27.230020      1.729692             23.956281\n",
      "std       49.276962      7.834730             44.168166\n",
      "min        1.000000      0.000000              0.000000\n",
      "25%        1.000000      1.000000              1.000000\n",
      "50%       16.000000      1.000000             15.000000\n",
      "75%       33.000000      1.000000             30.000000\n",
      "max     1344.000000    637.000000           1344.000000 \n",
      "\n",
      "Words per Line\n",
      "count    13751.000000\n",
      "mean        71.079127\n",
      "std        284.936695\n",
      "min          0.000000\n",
      "25%          6.062500\n",
      "50%          8.000000\n",
      "75%         69.000000\n",
      "max       9713.000000\n",
      "Name: avg_words_per_line, dtype: float64 \n",
      "\n",
      "Total Words per Poem\n",
      "count    13751.000000\n",
      "mean       251.321140\n",
      "std        442.320771\n",
      "min          0.000000\n",
      "25%         99.000000\n",
      "50%        153.000000\n",
      "75%        263.000000\n",
      "max      15713.000000\n",
      "Name: total_words, dtype: float64 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = stats(df)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7167f27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "Title: \\n=13134, \\r=13134, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=1\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n",
      "\n",
      "After cleaning\n",
      "Title: \\n=0, \\r=0, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=0\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load\n",
    "df = pd.read_csv(\"data/processed/final_clean.csv\")\n",
    "\n",
    "cols = ['Title', 'Poet', 'Tags']\n",
    "\n",
    "# before cleaning\n",
    "print(\"Before cleaning:\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "# cleaning\n",
    "for col in cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        # убираем любые переводы строки\n",
    "        .str.replace(r'[\\r\\n]+', ' ', regex=True)\n",
    "        # сводим множественные пробелы/табы в один пробел\n",
    "        .str.replace(r'[ \\t]+',   ' ', regex=True)\n",
    "        # убираем пробелы/табы по краям\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "print(\"\\nAfter cleaning\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "df.to_csv(\"data/processed/final_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2af77f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "Title: \\n=13134, \\r=13134, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=1\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n",
      "\n",
      "After cleaning\n",
      "Title: \\n=0, \\r=0, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=0\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load\n",
    "df = pd.read_csv(\"data/processed/final_clean.csv\")\n",
    "\n",
    "cols = ['Title', 'Poet', 'Tags']\n",
    "\n",
    "# before cleaning\n",
    "print(\"Before cleaning:\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "# cleaning\n",
    "for col in cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        # убираем любые переводы строки\n",
    "        .str.replace(r'[\\r\\n]+', ' ', regex=True)\n",
    "        # сводим множественные пробелы/табы в один пробел\n",
    "        .str.replace(r'[ \\t]+',   ' ', regex=True)\n",
    "        # убираем пробелы/табы по краям\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "print(\"\\nAfter cleaning\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "df.to_csv(\"data/processed/final_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbd612e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "Title: \\n=13134, \\r=13134, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=1\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n",
      "\n",
      "After cleaning\n",
      "Title: \\n=0, \\r=0, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=0\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load\n",
    "df = pd.read_csv(\"data/processed/final_clean.csv\")\n",
    "\n",
    "cols = ['Title', 'Poet', 'Tags']\n",
    "\n",
    "# before cleaning\n",
    "print(\"Before cleaning:\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "# cleaning\n",
    "for col in cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        # убираем любые переводы строки\n",
    "        .str.replace(r'[\\r\\n]+', ' ', regex=True)\n",
    "        # сводим множественные пробелы/табы в один пробел\n",
    "        .str.replace(r'[ \\t]+',   ' ', regex=True)\n",
    "        # убираем пробелы/табы по краям\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "print(\"\\nAfter cleaning\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "df.to_csv(\"data/processed/final_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e4b29b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "Title: \\n=13134, \\r=13134, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=1\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n",
      "\n",
      "After cleaning\n",
      "Title: \\n=0, \\r=0, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=0\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load\n",
    "df = pd.read_csv(\"data/processed/final_clean.csv\")\n",
    "\n",
    "cols = ['Title', 'Poet', 'Tags']\n",
    "\n",
    "# before cleaning\n",
    "print(\"Before cleaning:\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "# cleaning\n",
    "for col in cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        # убираем любые переводы строки\n",
    "        .str.replace(r'[\\r\\n]+', ' ', regex=True)\n",
    "        # сводим множественные пробелы/табы в один пробел\n",
    "        .str.replace(r'[ \\t]+',   ' ', regex=True)\n",
    "        # убираем пробелы/табы по краям\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "print(\"\\nAfter cleaning\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "df.to_csv(\"data/processed/final_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e19a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "Title: \\n=13134, \\r=13134, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=1\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n",
      "\n",
      "After cleaning\n",
      "Title: \\n=0, \\r=0, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=0\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load\n",
    "df = pd.read_csv(\"data/processed/final_clean.csv\")\n",
    "\n",
    "cols = ['Title', 'Poet', 'Tags']\n",
    "\n",
    "# before cleaning\n",
    "print(\"Before cleaning:\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "# cleaning\n",
    "for col in cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        # убираем любые переводы строки\n",
    "        .str.replace(r'[\\r\\n]+', ' ', regex=True)\n",
    "        # сводим множественные пробелы/табы в один пробел\n",
    "        .str.replace(r'[ \\t]+',   ' ', regex=True)\n",
    "        # убираем пробелы/табы по краям\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "print(\"\\nAfter cleaning\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "df.to_csv(\"data/processed/final_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e22a01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "Title: \\n=13134, \\r=13134, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=1\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n",
      "\n",
      "After cleaning\n",
      "Title: \\n=0, \\r=0, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=0\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load\n",
    "df = pd.read_csv(\"data/processed/final_clean.csv\")\n",
    "\n",
    "cols = ['Title', 'Poet', 'Tags']\n",
    "\n",
    "# before cleaning\n",
    "print(\"Before cleaning:\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "# cleaning\n",
    "for col in cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        # убираем любые переводы строки\n",
    "        .str.replace(r'[\\r\\n]+', ' ', regex=True)\n",
    "        # сводим множественные пробелы/табы в один пробел\n",
    "        .str.replace(r'[ \\t]+',   ' ', regex=True)\n",
    "        # убираем пробелы/табы по краям\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "print(\"\\nAfter cleaning\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "df.to_csv(\"data/processed/final_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc94d36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "Title: \\n=13134, \\r=13134, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=1\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n",
      "\n",
      "After cleaning\n",
      "Title: \\n=0, \\r=0, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=0\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load\n",
    "df = pd.read_csv(\"data/processed/final_clean.csv\")\n",
    "\n",
    "cols = ['Title', 'Poet', 'Tags']\n",
    "\n",
    "# before cleaning\n",
    "print(\"Before cleaning:\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "# cleaning\n",
    "for col in cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        # убираем любые переводы строки\n",
    "        .str.replace(r'[\\r\\n]+', ' ', regex=True)\n",
    "        # сводим множественные пробелы/табы в один пробел\n",
    "        .str.replace(r'[ \\t]+',   ' ', regex=True)\n",
    "        # убираем пробелы/табы по краям\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "print(\"\\nAfter cleaning\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "df.to_csv(\"data/processed/final_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5b0d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "Title: \\n=13134, \\r=13134, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=1\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n",
      "\n",
      "After cleaning\n",
      "Title: \\n=0, \\r=0, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=0\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load\n",
    "df = pd.read_csv(\"data/processed/final_clean.csv\")\n",
    "\n",
    "cols = ['Title', 'Poet', 'Tags']\n",
    "\n",
    "# before cleaning\n",
    "print(\"Before cleaning:\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "# cleaning\n",
    "for col in cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        # убираем любые переводы строки\n",
    "        .str.replace(r'[\\r\\n]+', ' ', regex=True)\n",
    "        # сводим множественные пробелы/табы в один пробел\n",
    "        .str.replace(r'[ \\t]+',   ' ', regex=True)\n",
    "        # убираем пробелы/табы по краям\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "print(\"\\nAfter cleaning\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "df.to_csv(\"data/processed/final_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b0c6de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "Title: \\n=13134, \\r=13134, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=1\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n",
      "\n",
      "After cleaning\n",
      "Title: \\n=0, \\r=0, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=0\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load\n",
    "df = pd.read_csv(\"data/processed/final_clean.csv\")\n",
    "\n",
    "cols = ['Title', 'Poet', 'Tags']\n",
    "\n",
    "# before cleaning\n",
    "print(\"Before cleaning:\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "# cleaning\n",
    "for col in cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        # убираем любые переводы строки\n",
    "        .str.replace(r'[\\r\\n]+', ' ', regex=True)\n",
    "        # сводим множественные пробелы/табы в один пробел\n",
    "        .str.replace(r'[ \\t]+',   ' ', regex=True)\n",
    "        # убираем пробелы/табы по краям\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "print(\"\\nAfter cleaning\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "df.to_csv(\"data/processed/final_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbc0204a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "Title: \\n=13134, \\r=13134, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=1\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n",
      "\n",
      "After cleaning\n",
      "Title: \\n=0, \\r=0, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=0\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load\n",
    "df = pd.read_csv(\"data/processed/final_clean.csv\")\n",
    "\n",
    "cols = ['Title', 'Poet', 'Tags']\n",
    "\n",
    "# before cleaning\n",
    "print(\"Before cleaning:\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "# cleaning\n",
    "for col in cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        # убираем любые переводы строки\n",
    "        .str.replace(r'[\\r\\n]+', ' ', regex=True)\n",
    "        # сводим множественные пробелы/табы в один пробел\n",
    "        .str.replace(r'[ \\t]+',   ' ', regex=True)\n",
    "        # убираем пробелы/табы по краям\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "print(\"\\nAfter cleaning\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "df.to_csv(\"data/processed/final_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7ca90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "Title: \\n=13134, \\r=13134, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=1\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n",
      "\n",
      "After cleaning\n",
      "Title: \\n=0, \\r=0, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=0\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load\n",
    "df = pd.read_csv(\"data/processed/final_clean.csv\")\n",
    "\n",
    "cols = ['Title', 'Poet', 'Tags']\n",
    "\n",
    "# before cleaning\n",
    "print(\"Before cleaning:\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "# cleaning\n",
    "for col in cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        # убираем любые переводы строки\n",
    "        .str.replace(r'[\\r\\n]+', ' ', regex=True)\n",
    "        # сводим множественные пробелы/табы в один пробел\n",
    "        .str.replace(r'[ \\t]+',   ' ', regex=True)\n",
    "        # убираем пробелы/табы по краям\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "print(\"\\nAfter cleaning\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "df.to_csv(\"data/processed/final_clean.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9976e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning:\n",
      "Title: \\n=13134, \\r=13134, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=1\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n",
      "\n",
      "After cleaning\n",
      "Title: \\n=0, \\r=0, leading_ws=0\n",
      "Poet: \\n=0, \\r=0, leading_ws=0\n",
      "Tags: \\n=0, \\r=0, leading_ws=0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# load\n",
    "df = pd.read_csv(\"data/processed/final_clean.csv\")\n",
    "\n",
    "cols = ['Title', 'Poet', 'Tags']\n",
    "\n",
    "# before cleaning\n",
    "print(\"Before cleaning:\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "# cleaning\n",
    "for col in cols:\n",
    "    df[col] = (\n",
    "        df[col]\n",
    "        # убираем любые переводы строки\n",
    "        .str.replace(r'[\\r\\n]+', ' ', regex=True)\n",
    "        # сводим множественные пробелы/табы в один пробел\n",
    "        .str.replace(r'[ \\t]+',   ' ', regex=True)\n",
    "        # убираем пробелы/табы по краям\n",
    "        .str.strip()\n",
    "    )\n",
    "\n",
    "print(\"\\nAfter cleaning\")\n",
    "for col in cols:\n",
    "    has_nl  = df[col].str.contains(r'\\n',   regex=True, na=False).sum()\n",
    "    has_cr  = df[col].str.contains(r'\\r',   regex=True, na=False).sum()\n",
    "    has_ws  = df[col].str.contains(r'^[ \\t]+', regex=True, na=False).sum()\n",
    "    print(f\"{col}: \\\\n={has_nl}, \\\\r={has_cr}, leading_ws={has_ws}\")\n",
    "\n",
    "df.to_csv(\"data/processed/final_clean.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
